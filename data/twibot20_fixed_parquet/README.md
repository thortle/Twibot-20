# Twibot-20 Processed Dataset (Parquet Format)

This directory contains the processed Twibot-20 dataset in Apache Parquet format, generated by `scripts/1_fix_dataset.py --use-parquet` or `scripts/convert_to_parquet.py`.

## Content

When generated, this directory will contain:
- `dataset_info.json`: Information about the dataset features and statistics
- `state.json`: Metadata about the dataset structure
- `train/`: Subdirectory containing the training split Parquet files
- `validation/`: Subdirectory containing the validation split Parquet files
- `test/`: Subdirectory containing the test split Parquet files

Each split subdirectory contains:
- `.parquet` files: Columnar storage format files containing the actual data

## Dataset Structure

The dataset contains the same columns as the Hugging Face format version:
- `user_id` (`string`): User identifier
- `text` (`string`): The combined, cleaned text from profile and tweets
- `features` (`string`): JSON string of the raw node data (for potential future use)
- `label` (`ClassLabel(names=['human', 'bot'])`): Integer label (0 or 1)

## Advantages of Parquet Format

- **Storage Efficiency**: Up to 14.59x smaller than the Hugging Face format
- **Columnar Access**: Efficient for operations that only need specific columns
- **Compression**: Built-in compression reduces storage requirements
- **Interoperability**: Works well with other data processing tools like Pandas, Spark, etc.

## Note

The actual data files are not included in this repository due to their large size. Run `scripts/1_fix_dataset.py --use-parquet` to generate them.
